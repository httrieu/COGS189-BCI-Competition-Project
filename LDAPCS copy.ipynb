{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from pathlib import Path\n",
    "import mne\n",
    "from util import *\n",
    "from scipy.signal import butter, sosfiltfilt, sosfreqz  # for filtering\n",
    "import matplotlib.pyplot as plt   \n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(189)\n",
    "rand_nums = np.random.permutation(6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "def butter_bandpass(lowcut, highcut, fs, order = 2):\n",
    "        nyq = 0.5 * fs\n",
    "        low = lowcut / nyq\n",
    "        high = highcut / nyq\n",
    "        sos = butter(order, [low, high], analog = False, btype = 'band', output = 'sos')\n",
    "        return sos\n",
    "\n",
    "def butter_bandpass_filter(data, lowcut, highcut, fs, order = 2):\n",
    "        sos = butter_bandpass(lowcut, highcut, fs, order = order)\n",
    "        y = sosfiltfilt(sos, data)\n",
    "        return y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting EDF parameters from C:\\Users\\hunte\\Documents\\COGS189-BCI-Competition-Project\\BCICIV_2a_gdf\\A01T.gdf...\n",
      "GDF file detected\n",
      "Setting channel info structure...\n",
      "Could not determine channel type of the following channels, they will be set as EEG:\n",
      "EEG-Fz, EEG, EEG, EEG, EEG, EEG, EEG, EEG-C3, EEG, EEG-Cz, EEG, EEG-C4, EEG, EEG, EEG, EEG, EEG, EEG, EEG, EEG-Pz, EEG, EEG, EOG-left, EOG-central, EOG-right\n",
      "Creating raw.info structure...\n",
      "Reading 0 ... 672527  =      0.000 ...  2690.108 secs...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\hunte\\anaconda3\\envs\\CSE156\\Lib\\contextlib.py:144: RuntimeWarning: Channel names are not unique, found duplicates for: {'EEG'}. Applying running numbers for duplicates.\n",
      "  next(self.gen)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Used Annotations descriptions: ['1023', '1072', '276', '277', '32766', '768', '769', '770', '771', '772']\n"
     ]
    }
   ],
   "source": [
    "# Path to GDF files\n",
    "gdf_folder = Path(\"BCICIV_2a_gdf\")\n",
    "\n",
    "gdf_path = gdf_folder / \"A01T.gdf\"\n",
    "\n",
    "# Users and target events\n",
    "target_events = {'769': 'left', '770': 'right', '771': 'feet', '772': 'tongue'}\n",
    "\n",
    "user_event_ids = {target_events[key]: event_id_map[key] for key in target_events if key in event_id_map}\n",
    "\n",
    "# Load raw data and extract events\n",
    "raw = mne.io.read_raw_gdf(gdf_path.resolve(), preload=True)\n",
    "events, event_ids = mne.events_from_annotations(raw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Not setting metadata\n",
      "288 matching events found\n",
      "Setting baseline interval to [-1.0, 0.0] s\n",
      "Applying baseline correction (mode: mean)\n",
      "0 projection items activated\n",
      "Using data from preloaded Raw for 288 events and 1251 original time points ...\n",
      "0 bad epochs dropped\n"
     ]
    }
   ],
   "source": [
    "data = []\n",
    "\n",
    "# Create epochs\n",
    "epochs = mne.Epochs(raw, events, event_id=user_event_ids, baseline=(None, 0), event_repeated='merge', preload=True, tmin=-1, tmax=4)\n",
    "labels = epochs.events[:, -1]  # Last column contains the event ID\n",
    "\n",
    "# Collect data and labels\n",
    "data.append(epochs.get_data())  # Shape: (n_trials, n_channels, n_times)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(288, 22, 1251)"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = np.concatenate(data, axis=0)\n",
    "data = data[:, :-3, :]\n",
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([10,  9,  8,  7,  7,  8,  9, 10,  8,  9])"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((72, 22, 1251), (72, 22, 1251), (72, 22, 1251), (72, 22, 1251))"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_left = []\n",
    "data_right = []\n",
    "data_feet = []\n",
    "data_tongue = []\n",
    "\n",
    "for i in range(len(labels)):\n",
    "    if labels[i] == 7:\n",
    "        data_left.append(data[i])\n",
    "    elif labels[i] == 8:\n",
    "        data_right.append(data[i])\n",
    "    elif labels[i] == 9:\n",
    "        data_feet.append(data[i])\n",
    "    else:\n",
    "        data_tongue.append(data[i])\n",
    "\n",
    "data_left = np.array(data_left)\n",
    "data_right = np.array(data_right)\n",
    "data_feet = np.array(data_feet)\n",
    "data_tongue = np.array(data_tongue)\n",
    "\n",
    "data_left.shape, data_right.shape, data_feet.shape, data_tongue.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([10,  9,  8,  7,  7,  8,  9, 10,  8,  9,  7,  7,  7, 10,  8,  8,  7,\n",
       "        7,  9,  7,  8, 10, 10,  9,  7, 10, 10,  8, 10, 10,  8,  7,  8,  9,\n",
       "        9,  9, 10,  9,  7, 10,  8,  9,  8,  9, 10,  8,  9,  7,  7,  7, 10,\n",
       "        8,  7,  9,  7,  9,  8, 10,  7,  9,  9,  7,  9,  8, 10, 10, 10,  9,\n",
       "        7, 10,  8, 10,  8,  7,  9,  8,  7,  9,  9,  7,  9, 10, 10,  8,  7,\n",
       "        8, 10,  8, 10,  9,  8,  8,  8,  9, 10,  7,  8, 10,  7,  9,  9, 10,\n",
       "        7,  7,  9,  8, 10, 10, 10,  8,  7,  9,  8, 10,  7, 10,  9,  8, 10,\n",
       "       10,  7,  8,  8,  9, 10,  8,  7,  7, 10,  8,  7,  9,  8,  8,  9,  7,\n",
       "       10,  9,  9,  9,  9,  7,  8,  7,  8,  7,  7,  9,  9,  8,  9, 10,  7,\n",
       "       10,  7,  7,  8, 10,  9,  8, 10,  9, 10,  9, 10,  8,  8, 10,  7,  8,\n",
       "        8,  8,  9, 10,  7, 10,  7,  9,  7, 10,  7,  9,  7,  8,  9,  9, 10,\n",
       "        7,  8, 10,  8,  9,  9,  7, 10,  8, 10,  7,  7,  9,  9,  8, 10,  8,\n",
       "        8,  7,  8, 10, 10,  8,  8,  8,  8, 10, 10,  9, 10,  7,  8,  9,  8,\n",
       "        7, 10,  7, 10,  7,  7,  7,  7,  9,  9, 10,  8,  9,  9,  9, 10,  9,\n",
       "        7,  9,  7, 10,  8, 10, 10,  9, 10, 10,  9,  8, 10,  9,  7,  8,  8,\n",
       "        8,  9,  8, 10,  9, 10,  8,  9,  7, 10,  7,  9, 10,  7,  9,  7,  8,\n",
       "        8,  7, 10,  7, 10,  9,  9,  7,  9,  8,  8,  7,  9,  7,  8,  7])"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#n_channel, n_time, n_sample = EEGR_train[0][0].shape\n",
    "randIdx = np.random.permutation(n_sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Our k is: 6\n",
      "Our bin size is: 12\n",
      "[[56 70 31 50 66 34 63  4 54  9 43 53]\n",
      " [52 16 14 21 10 64 41 47 28  5 20 42]\n",
      " [13 33  7 59 18 71 49 22 68 26 61 32]\n",
      " [ 6 46  3 48 44  8 11 15 17  1 24  0]\n",
      " [30 65 12  2 27 37 55 23 69 67 39 57]\n",
      " [36 29 45 60 38 40 51 62 19 25 58 35]]\n"
     ]
    }
   ],
   "source": [
    "k = 6\n",
    "print(f'Our k is: {k}')\n",
    "\n",
    "bin_size = int(n_sample / k)\n",
    "print(f'Our bin size is: {bin_size}')\n",
    "\n",
    "# In order to make our task easier, \n",
    "# we can reshape randIdx to have k rows and bin_size columns\n",
    "# by using .reshape():\n",
    "randIdx = randIdx.reshape(k, bin_size)\n",
    "print(randIdx)\n",
    "assert np.array_equal(randIdx,\n",
    "                      np.array([[56, 70, 31, 50, 66, 34, 63,  4, 54,  9, 43, 53],\n",
    "                                [52, 16, 14, 21, 10, 64, 41, 47, 28,  5, 20, 42],\n",
    "                                [13, 33,  7, 59, 18, 71, 49, 22, 68, 26, 61, 32],\n",
    "                                [ 6, 46,  3, 48, 44,  8, 11, 15, 17,  1, 24,  0],\n",
    "                                [30, 65, 12,  2, 27, 37, 55, 23, 69, 67, 39, 57],\n",
    "                                [36, 29, 45, 60, 38, 40, 51, 62, 19, 25, 58, 35]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainIdx = np.zeros((k, bin_size*(k-1)), dtype=int)\n",
    "valIdx = np.zeros((k, bin_size), dtype=int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[56, 70, 31, 50, 66, 34, 63,  4, 54,  9, 43, 53],\n",
       "       [39, 59,  5,  7, 32, 36, 68,  9, 12, 60, 58, 10],\n",
       "       [27, 35, 25, 63, 22, 49,  3, 20, 34, 33,  5, 28],\n",
       "       [ 9, 36,  4, 18, 31, 54, 49, 30, 58, 42, 22, 34],\n",
       "       [53, 34, 63, 10, 39, 61,  4, 51, 36, 69, 48, 23],\n",
       "       [41,  6, 10, 23, 19, 29, 30, 59, 49, 39, 71, 51]])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# We'll reset trainIdx and valIdx (just in case)\n",
    "# Note: feel free to use uninitialized lists and append\n",
    "#       this is just one possible starting point to show\n",
    "#       the correct size of these objects.\n",
    "trainIdx = np.zeros((k, bin_size*(k-1)), dtype=int) # could also be = []\n",
    "valIdx = np.zeros((k, bin_size), dtype=int)           # could also be = []\n",
    "\n",
    "# --- Question 4 ---\n",
    "# YOUR CODE HERE\n",
    "\n",
    "for i in range(k):\n",
    "    lst = []\n",
    "    for row in range(k):\n",
    "        if row == 0:\n",
    "            valIdx[i] = randIdx[row]\n",
    "            continue\n",
    "        for col in range(len(randIdx[0])):\n",
    "            lst.append(randIdx[row][col])\n",
    "    trainIdx[i] = lst\n",
    "    randIdx = np.random.permutation(n_sample)\n",
    "    randIdx = randIdx.reshape(k, bin_size)\n",
    "valIdx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Depending on your solution, valIdx and trainIdx may not be np.arrays\n",
    "# Let's guarantee they are\n",
    "valIdx = np.array(valIdx)\n",
    "trainIdx = np.array(trainIdx)\n",
    "\n",
    "assert valIdx.shape == (k, bin_size)\n",
    "assert trainIdx.shape == (k, bin_size*(k-1))\n",
    "\n",
    "assert np.array_equal(valIdx[0,:], np.array([56, 70, 31, 50, 66, 34, 63,  4, 54,  9, 43, 53]))\n",
    "assert np.array_equal(trainIdx[0,:], np.array([52, 16, 14, 21, 10, 64, 41, 47, 28,  5, 20, 42, 13, 33,  7, 59, 18,\n",
    "                                               71, 49, 22, 68, 26, 61, 32,  6, 46,  3, 48, 44,  8, 11, 15, 17,  1,\n",
    "                                               24,  0, 30, 65, 12,  2, 27, 37, 55, 23, 69, 67, 39, 57, 36, 29, 45,\n",
    "                                               60, 38, 40, 51, 62, 19, 25, 58, 35]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===============\n",
      "Processing Subject 1/9\n",
      "Processing Fold 1/6\n",
      "Processing Fold 2/6\n",
      "Processing Fold 3/6\n",
      "Processing Fold 4/6\n",
      "Processing Fold 5/6\n",
      "Processing Fold 6/6\n",
      "===============\n",
      "Processing Subject 2/9\n",
      "Processing Fold 1/6\n",
      "Processing Fold 2/6\n",
      "Processing Fold 3/6\n",
      "Processing Fold 4/6\n",
      "Processing Fold 5/6\n",
      "Processing Fold 6/6\n",
      "===============\n",
      "Processing Subject 3/9\n",
      "Processing Fold 1/6\n",
      "Processing Fold 2/6\n",
      "Processing Fold 3/6\n",
      "Processing Fold 4/6\n",
      "Processing Fold 5/6\n",
      "Processing Fold 6/6\n",
      "===============\n",
      "Processing Subject 4/9\n",
      "Processing Fold 1/6\n",
      "Processing Fold 2/6\n",
      "Processing Fold 3/6\n",
      "Processing Fold 4/6\n",
      "Processing Fold 5/6\n",
      "Processing Fold 6/6\n",
      "===============\n",
      "Processing Subject 5/9\n",
      "Processing Fold 1/6\n",
      "Processing Fold 2/6\n",
      "Processing Fold 3/6\n",
      "Processing Fold 4/6\n",
      "Processing Fold 5/6\n",
      "Processing Fold 6/6\n",
      "===============\n",
      "Processing Subject 6/9\n",
      "Processing Fold 1/6\n",
      "Processing Fold 2/6\n",
      "Processing Fold 3/6\n",
      "Processing Fold 4/6\n",
      "Processing Fold 5/6\n",
      "Processing Fold 6/6\n",
      "===============\n",
      "Processing Subject 7/9\n",
      "Processing Fold 1/6\n",
      "Processing Fold 2/6\n",
      "Processing Fold 3/6\n",
      "Processing Fold 4/6\n",
      "Processing Fold 5/6\n",
      "Processing Fold 6/6\n",
      "===============\n",
      "Processing Subject 8/9\n",
      "Processing Fold 1/6\n",
      "Processing Fold 2/6\n",
      "Processing Fold 3/6\n",
      "Processing Fold 4/6\n",
      "Processing Fold 5/6\n",
      "Processing Fold 6/6\n",
      "===============\n",
      "Processing Subject 9/9\n",
      "Processing Fold 1/6\n",
      "Processing Fold 2/6\n",
      "Processing Fold 3/6\n",
      "Processing Fold 4/6\n",
      "Processing Fold 5/6\n",
      "Processing Fold 6/6\n",
      "===============\n",
      "[0.92361111 0.5        0.94444444 0.79166667 0.875      0.77083333\n",
      " 0.96527778 0.97222222 0.94444444]\n"
     ]
    }
   ],
   "source": [
    "# Main Analysis (Do Not Modify)\n",
    "\n",
    "# Declare useful variables\n",
    "n_subjects, n_filters = EEGL_train.shape\n",
    "train_size = bin_size * (k-1)\n",
    "val_size = bin_size\n",
    "accuracy = np.zeros((n_subjects, k))\n",
    "csp_per_class = 3\n",
    "trainIdx = trainIdx.astype(int)\n",
    "valIdx = valIdx.astype(int)\n",
    "\n",
    "# Begin nested loops\n",
    "# Subject > Fold > Band\n",
    "print('===============')\n",
    "for subject in range(n_subjects):\n",
    "    print('Processing Subject {}/{}'.format(subject+1, n_subjects))\n",
    "    for fold in range(k):\n",
    "        print('Processing Fold {}/{}'.format(fold+1, k))\n",
    "        band_score_train = np.zeros((train_size*2, n_filters))\n",
    "        band_score_val = np.zeros((val_size*2, n_filters))\n",
    "        for band in range(n_filters):\n",
    "            # train,val dataset -> train,val for each subject&band\n",
    "            L_train = EEGL_train[subject, band][:,:,trainIdx[fold]].transpose(2,0,1) # (trials, chans, samples)\n",
    "            R_train = EEGR_train[subject, band][:,:,trainIdx[fold]].transpose(2,0,1) # (trials, chans, samples)\n",
    "            L_val = EEGL_train[subject, band][:,:,valIdx[fold]].transpose(2,0,1) # (trials, chans, samples)\n",
    "            R_val = EEGR_train[subject, band][:,:,valIdx[fold]].transpose(2,0,1) # (trials, chans, samples)\n",
    "            train_data = np.stack((L_train,R_train), axis=0) # <- CSP input data format (classes, trials, chans, samples) \n",
    "            val_data = np.stack((L_val,R_val), axis=0) # <- CSP input data format (classes, trials, chans, samples)\n",
    "\n",
    "            # Run Mahta's CSP code\n",
    "            # Source: https://github.com/mahtamsv/CCACSP\n",
    "            csp_filts, clf = train(train_data[0], train_data[1], csp_per_class)\n",
    "            train_prob = test(np.vstack(train_data), csp_filts, clf)\n",
    "            val_prob = test(np.vstack(val_data), csp_filts, clf)\n",
    "            \n",
    "            # test() gives the prob of the 0th class, that's why \n",
    "            # we have y_val seemingly switched below\n",
    "            y_val = np.append(np.ones(12), np.zeros(12))\n",
    "\n",
    "            band_score_train[:,band] = train_prob\n",
    "            band_score_val[:,band] = val_prob\n",
    "        \n",
    "        \n",
    "        accuracy[subject,fold] = sum(np.rint(band_score_val.mean(1))==y_val)/len(y_val)\n",
    "    print('===============')\n",
    "print(np.mean(accuracy, axis=1))\n",
    "\n",
    "# Main Analysis Over"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "CSE156",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
