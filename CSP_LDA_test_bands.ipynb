{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from pathlib import Path\n",
    "import mne\n",
    "from util import *\n",
    "from scipy.signal import butter, sosfiltfilt, sosfreqz  # for filtering\n",
    "import matplotlib.pyplot as plt   \n",
    "import pandas as pd\n",
    "from sklearn.metrics import cohen_kappa_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_sample = 72\n",
    "k = 6\n",
    "bin_size = int(n_sample / k)\n",
    "#n_channel, n_time, n_sample = EEGR_train[0][0].shape\n",
    "randIdx = np.random.permutation(n_sample)\n",
    "randIdx = randIdx.reshape(k, bin_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Processing A01T.gdf...\n",
      "Extracting EDF parameters from F:\\COGS189-BCI-Competition-Project\\BCICIV_2a_gdf\\A01T.gdf...\n",
      "GDF file detected\n",
      "Setting channel info structure...\n",
      "Could not determine channel type of the following channels, they will be set as EEG:\n",
      "EEG-Fz, EEG, EEG, EEG, EEG, EEG, EEG, EEG-C3, EEG, EEG-Cz, EEG, EEG-C4, EEG, EEG, EEG, EEG, EEG, EEG, EEG, EEG-Pz, EEG, EEG, EOG-left, EOG-central, EOG-right\n",
      "Creating raw.info structure...\n",
      "Reading 0 ... 672527  =      0.000 ...  2690.108 secs...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "f:\\Anaconda\\envs\\CSE156\\Lib\\contextlib.py:144: RuntimeWarning: Channel names are not unique, found duplicates for: {'EEG'}. Applying running numbers for duplicates.\n",
      "  next(self.gen)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Used Annotations descriptions: ['1023', '1072', '276', '277', '32766', '768', '769', '770', '771', '772']\n",
      "  Filtering 2-5 Hz...\n",
      "Filtering raw data in 1 contiguous segment\n",
      "Setting up band-pass filter from 2 - 5 Hz\n",
      "\n",
      "FIR filter parameters\n",
      "---------------------\n",
      "Designing a one-pass, zero-phase, non-causal bandpass filter:\n",
      "- Windowed time-domain design (firwin) method\n",
      "- Hamming window with 0.0194 passband ripple and 53 dB stopband attenuation\n",
      "- Lower passband edge: 2.00\n",
      "- Lower transition bandwidth: 2.00 Hz (-6 dB cutoff frequency: 1.00 Hz)\n",
      "- Upper passband edge: 5.00 Hz\n",
      "- Upper transition bandwidth: 2.00 Hz (-6 dB cutoff frequency: 6.00 Hz)\n",
      "- Filter length: 413 samples (1.652 s)\n",
      "\n",
      "Not setting metadata\n",
      "288 matching events found\n",
      "Setting baseline interval to [-0.3, 0.0] s\n",
      "Applying baseline correction (mode: mean)\n",
      "0 projection items activated\n",
      "Using data from preloaded Raw for 288 events and 1076 original time points ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  17 tasks      | elapsed:    0.2s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 bad epochs dropped\n",
      "\n",
      "Processing A02T.gdf...\n",
      "Extracting EDF parameters from F:\\COGS189-BCI-Competition-Project\\BCICIV_2a_gdf\\A02T.gdf...\n",
      "GDF file detected\n",
      "Setting channel info structure...\n",
      "Could not determine channel type of the following channels, they will be set as EEG:\n",
      "EEG-Fz, EEG, EEG, EEG, EEG, EEG, EEG, EEG-C3, EEG, EEG-Cz, EEG, EEG-C4, EEG, EEG, EEG, EEG, EEG, EEG, EEG, EEG-Pz, EEG, EEG, EOG-left, EOG-central, EOG-right\n",
      "Creating raw.info structure...\n",
      "Reading 0 ... 677168  =      0.000 ...  2708.672 secs...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "f:\\Anaconda\\envs\\CSE156\\Lib\\contextlib.py:144: RuntimeWarning: Channel names are not unique, found duplicates for: {'EEG'}. Applying running numbers for duplicates.\n",
      "  next(self.gen)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Used Annotations descriptions: ['1023', '1072', '276', '277', '32766', '768', '769', '770', '771', '772']\n",
      "  Filtering 2-5 Hz...\n",
      "Filtering raw data in 1 contiguous segment\n",
      "Setting up band-pass filter from 2 - 5 Hz\n",
      "\n",
      "FIR filter parameters\n",
      "---------------------\n",
      "Designing a one-pass, zero-phase, non-causal bandpass filter:\n",
      "- Windowed time-domain design (firwin) method\n",
      "- Hamming window with 0.0194 passband ripple and 53 dB stopband attenuation\n",
      "- Lower passband edge: 2.00\n",
      "- Lower transition bandwidth: 2.00 Hz (-6 dB cutoff frequency: 1.00 Hz)\n",
      "- Upper passband edge: 5.00 Hz\n",
      "- Upper transition bandwidth: 2.00 Hz (-6 dB cutoff frequency: 6.00 Hz)\n",
      "- Filter length: 413 samples (1.652 s)\n",
      "\n",
      "Not setting metadata\n",
      "288 matching events found\n",
      "Setting baseline interval to [-0.3, 0.0] s\n",
      "Applying baseline correction (mode: mean)\n",
      "0 projection items activated\n",
      "Using data from preloaded Raw for 288 events and 1076 original time points ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  17 tasks      | elapsed:    0.2s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 bad epochs dropped\n",
      "\n",
      "Processing A03T.gdf...\n",
      "Extracting EDF parameters from F:\\COGS189-BCI-Competition-Project\\BCICIV_2a_gdf\\A03T.gdf...\n",
      "GDF file detected\n",
      "Setting channel info structure...\n",
      "Could not determine channel type of the following channels, they will be set as EEG:\n",
      "EEG-Fz, EEG, EEG, EEG, EEG, EEG, EEG, EEG-C3, EEG, EEG-Cz, EEG, EEG-C4, EEG, EEG, EEG, EEG, EEG, EEG, EEG, EEG-Pz, EEG, EEG, EOG-left, EOG-central, EOG-right\n",
      "Creating raw.info structure...\n",
      "Reading 0 ... 660529  =      0.000 ...  2642.116 secs...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "f:\\Anaconda\\envs\\CSE156\\Lib\\contextlib.py:144: RuntimeWarning: Channel names are not unique, found duplicates for: {'EEG'}. Applying running numbers for duplicates.\n",
      "  next(self.gen)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Used Annotations descriptions: ['1023', '1072', '276', '277', '32766', '768', '769', '770', '771', '772']\n",
      "  Filtering 2-5 Hz...\n",
      "Filtering raw data in 1 contiguous segment\n",
      "Setting up band-pass filter from 2 - 5 Hz\n",
      "\n",
      "FIR filter parameters\n",
      "---------------------\n",
      "Designing a one-pass, zero-phase, non-causal bandpass filter:\n",
      "- Windowed time-domain design (firwin) method\n",
      "- Hamming window with 0.0194 passband ripple and 53 dB stopband attenuation\n",
      "- Lower passband edge: 2.00\n",
      "- Lower transition bandwidth: 2.00 Hz (-6 dB cutoff frequency: 1.00 Hz)\n",
      "- Upper passband edge: 5.00 Hz\n",
      "- Upper transition bandwidth: 2.00 Hz (-6 dB cutoff frequency: 6.00 Hz)\n",
      "- Filter length: 413 samples (1.652 s)\n",
      "\n",
      "Not setting metadata\n",
      "288 matching events found\n",
      "Setting baseline interval to [-0.3, 0.0] s\n",
      "Applying baseline correction (mode: mean)\n",
      "0 projection items activated\n",
      "Using data from preloaded Raw for 288 events and 1076 original time points ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  17 tasks      | elapsed:    0.2s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 bad epochs dropped\n",
      "\n",
      "Processing A05T.gdf...\n",
      "Extracting EDF parameters from F:\\COGS189-BCI-Competition-Project\\BCICIV_2a_gdf\\A05T.gdf...\n",
      "GDF file detected\n",
      "Setting channel info structure...\n",
      "Could not determine channel type of the following channels, they will be set as EEG:\n",
      "EEG-Fz, EEG, EEG, EEG, EEG, EEG, EEG, EEG-C3, EEG, EEG-Cz, EEG, EEG-C4, EEG, EEG, EEG, EEG, EEG, EEG, EEG, EEG-Pz, EEG, EEG, EOG-left, EOG-central, EOG-right\n",
      "Creating raw.info structure...\n",
      "Reading 0 ... 686119  =      0.000 ...  2744.476 secs...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "f:\\Anaconda\\envs\\CSE156\\Lib\\contextlib.py:144: RuntimeWarning: Channel names are not unique, found duplicates for: {'EEG'}. Applying running numbers for duplicates.\n",
      "  next(self.gen)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Used Annotations descriptions: ['1023', '1072', '276', '277', '32766', '768', '769', '770', '771', '772']\n",
      "  Filtering 2-5 Hz...\n",
      "Filtering raw data in 1 contiguous segment\n",
      "Setting up band-pass filter from 2 - 5 Hz\n",
      "\n",
      "FIR filter parameters\n",
      "---------------------\n",
      "Designing a one-pass, zero-phase, non-causal bandpass filter:\n",
      "- Windowed time-domain design (firwin) method\n",
      "- Hamming window with 0.0194 passband ripple and 53 dB stopband attenuation\n",
      "- Lower passband edge: 2.00\n",
      "- Lower transition bandwidth: 2.00 Hz (-6 dB cutoff frequency: 1.00 Hz)\n",
      "- Upper passband edge: 5.00 Hz\n",
      "- Upper transition bandwidth: 2.00 Hz (-6 dB cutoff frequency: 6.00 Hz)\n",
      "- Filter length: 413 samples (1.652 s)\n",
      "\n",
      "Not setting metadata\n",
      "288 matching events found\n",
      "Setting baseline interval to [-0.3, 0.0] s\n",
      "Applying baseline correction (mode: mean)\n",
      "0 projection items activated\n",
      "Using data from preloaded Raw for 288 events and 1076 original time points ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  17 tasks      | elapsed:    0.2s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 bad epochs dropped\n",
      "\n",
      "Processing A06T.gdf...\n",
      "Extracting EDF parameters from F:\\COGS189-BCI-Competition-Project\\BCICIV_2a_gdf\\A06T.gdf...\n",
      "GDF file detected\n",
      "Setting channel info structure...\n",
      "Could not determine channel type of the following channels, they will be set as EEG:\n",
      "EEG-Fz, EEG, EEG, EEG, EEG, EEG, EEG, EEG-C3, EEG, EEG-Cz, EEG, EEG-C4, EEG, EEG, EEG, EEG, EEG, EEG, EEG, EEG-Pz, EEG, EEG, EOG-left, EOG-central, EOG-right\n",
      "Creating raw.info structure...\n",
      "Reading 0 ... 678979  =      0.000 ...  2715.916 secs...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "f:\\Anaconda\\envs\\CSE156\\Lib\\contextlib.py:144: RuntimeWarning: Channel names are not unique, found duplicates for: {'EEG'}. Applying running numbers for duplicates.\n",
      "  next(self.gen)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Used Annotations descriptions: ['1023', '1072', '276', '277', '32766', '768', '769', '770', '771', '772']\n",
      "  Filtering 2-5 Hz...\n",
      "Filtering raw data in 1 contiguous segment\n",
      "Setting up band-pass filter from 2 - 5 Hz\n",
      "\n",
      "FIR filter parameters\n",
      "---------------------\n",
      "Designing a one-pass, zero-phase, non-causal bandpass filter:\n",
      "- Windowed time-domain design (firwin) method\n",
      "- Hamming window with 0.0194 passband ripple and 53 dB stopband attenuation\n",
      "- Lower passband edge: 2.00\n",
      "- Lower transition bandwidth: 2.00 Hz (-6 dB cutoff frequency: 1.00 Hz)\n",
      "- Upper passband edge: 5.00 Hz\n",
      "- Upper transition bandwidth: 2.00 Hz (-6 dB cutoff frequency: 6.00 Hz)\n",
      "- Filter length: 413 samples (1.652 s)\n",
      "\n",
      "Not setting metadata\n",
      "288 matching events found\n",
      "Setting baseline interval to [-0.3, 0.0] s\n",
      "Applying baseline correction (mode: mean)\n",
      "0 projection items activated\n",
      "Using data from preloaded Raw for 288 events and 1076 original time points ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  17 tasks      | elapsed:    0.2s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 bad epochs dropped\n",
      "\n",
      "Processing A07T.gdf...\n",
      "Extracting EDF parameters from F:\\COGS189-BCI-Competition-Project\\BCICIV_2a_gdf\\A07T.gdf...\n",
      "GDF file detected\n",
      "Setting channel info structure...\n",
      "Could not determine channel type of the following channels, they will be set as EEG:\n",
      "EEG-Fz, EEG, EEG, EEG, EEG, EEG, EEG, EEG-C3, EEG, EEG-Cz, EEG, EEG-C4, EEG, EEG, EEG, EEG, EEG, EEG, EEG, EEG-Pz, EEG, EEG, EOG-left, EOG-central, EOG-right\n",
      "Creating raw.info structure...\n",
      "Reading 0 ... 681070  =      0.000 ...  2724.280 secs...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "f:\\Anaconda\\envs\\CSE156\\Lib\\contextlib.py:144: RuntimeWarning: Channel names are not unique, found duplicates for: {'EEG'}. Applying running numbers for duplicates.\n",
      "  next(self.gen)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Used Annotations descriptions: ['1023', '1072', '276', '277', '32766', '768', '769', '770', '771', '772']\n",
      "  Filtering 2-5 Hz...\n",
      "Filtering raw data in 1 contiguous segment\n",
      "Setting up band-pass filter from 2 - 5 Hz\n",
      "\n",
      "FIR filter parameters\n",
      "---------------------\n",
      "Designing a one-pass, zero-phase, non-causal bandpass filter:\n",
      "- Windowed time-domain design (firwin) method\n",
      "- Hamming window with 0.0194 passband ripple and 53 dB stopband attenuation\n",
      "- Lower passband edge: 2.00\n",
      "- Lower transition bandwidth: 2.00 Hz (-6 dB cutoff frequency: 1.00 Hz)\n",
      "- Upper passband edge: 5.00 Hz\n",
      "- Upper transition bandwidth: 2.00 Hz (-6 dB cutoff frequency: 6.00 Hz)\n",
      "- Filter length: 413 samples (1.652 s)\n",
      "\n",
      "Not setting metadata\n",
      "288 matching events found\n",
      "Setting baseline interval to [-0.3, 0.0] s\n",
      "Applying baseline correction (mode: mean)\n",
      "0 projection items activated\n",
      "Using data from preloaded Raw for 288 events and 1076 original time points ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  17 tasks      | elapsed:    0.2s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 bad epochs dropped\n",
      "\n",
      "Processing A08T.gdf...\n",
      "Extracting EDF parameters from F:\\COGS189-BCI-Competition-Project\\BCICIV_2a_gdf\\A08T.gdf...\n",
      "GDF file detected\n",
      "Setting channel info structure...\n",
      "Could not determine channel type of the following channels, they will be set as EEG:\n",
      "EEG-Fz, EEG, EEG, EEG, EEG, EEG, EEG, EEG-C3, EEG, EEG-Cz, EEG, EEG-C4, EEG, EEG, EEG, EEG, EEG, EEG, EEG, EEG-Pz, EEG, EEG, EOG-left, EOG-central, EOG-right\n",
      "Creating raw.info structure...\n",
      "Reading 0 ... 675269  =      0.000 ...  2701.076 secs...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "f:\\Anaconda\\envs\\CSE156\\Lib\\contextlib.py:144: RuntimeWarning: Channel names are not unique, found duplicates for: {'EEG'}. Applying running numbers for duplicates.\n",
      "  next(self.gen)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Used Annotations descriptions: ['1023', '1072', '276', '277', '32766', '768', '769', '770', '771', '772']\n",
      "  Filtering 2-5 Hz...\n",
      "Filtering raw data in 1 contiguous segment\n",
      "Setting up band-pass filter from 2 - 5 Hz\n",
      "\n",
      "FIR filter parameters\n",
      "---------------------\n",
      "Designing a one-pass, zero-phase, non-causal bandpass filter:\n",
      "- Windowed time-domain design (firwin) method\n",
      "- Hamming window with 0.0194 passband ripple and 53 dB stopband attenuation\n",
      "- Lower passband edge: 2.00\n",
      "- Lower transition bandwidth: 2.00 Hz (-6 dB cutoff frequency: 1.00 Hz)\n",
      "- Upper passband edge: 5.00 Hz\n",
      "- Upper transition bandwidth: 2.00 Hz (-6 dB cutoff frequency: 6.00 Hz)\n",
      "- Filter length: 413 samples (1.652 s)\n",
      "\n",
      "Not setting metadata\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  17 tasks      | elapsed:    0.2s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "288 matching events found\n",
      "Setting baseline interval to [-0.3, 0.0] s\n",
      "Applying baseline correction (mode: mean)\n",
      "0 projection items activated\n",
      "Using data from preloaded Raw for 288 events and 1076 original time points ...\n",
      "0 bad epochs dropped\n",
      "\n",
      "Processing A09T.gdf...\n",
      "Extracting EDF parameters from F:\\COGS189-BCI-Competition-Project\\BCICIV_2a_gdf\\A09T.gdf...\n",
      "GDF file detected\n",
      "Setting channel info structure...\n",
      "Could not determine channel type of the following channels, they will be set as EEG:\n",
      "EEG-Fz, EEG, EEG, EEG, EEG, EEG, EEG, EEG-C3, EEG, EEG-Cz, EEG, EEG-C4, EEG, EEG, EEG, EEG, EEG, EEG, EEG, EEG-Pz, EEG, EEG, EOG-left, EOG-central, EOG-right\n",
      "Creating raw.info structure...\n",
      "Reading 0 ... 673327  =      0.000 ...  2693.308 secs...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "f:\\Anaconda\\envs\\CSE156\\Lib\\contextlib.py:144: RuntimeWarning: Channel names are not unique, found duplicates for: {'EEG'}. Applying running numbers for duplicates.\n",
      "  next(self.gen)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Used Annotations descriptions: ['1023', '1072', '276', '277', '32766', '768', '769', '770', '771', '772']\n",
      "  Filtering 2-5 Hz...\n",
      "Filtering raw data in 1 contiguous segment\n",
      "Setting up band-pass filter from 2 - 5 Hz\n",
      "\n",
      "FIR filter parameters\n",
      "---------------------\n",
      "Designing a one-pass, zero-phase, non-causal bandpass filter:\n",
      "- Windowed time-domain design (firwin) method\n",
      "- Hamming window with 0.0194 passband ripple and 53 dB stopband attenuation\n",
      "- Lower passband edge: 2.00\n",
      "- Lower transition bandwidth: 2.00 Hz (-6 dB cutoff frequency: 1.00 Hz)\n",
      "- Upper passband edge: 5.00 Hz\n",
      "- Upper transition bandwidth: 2.00 Hz (-6 dB cutoff frequency: 6.00 Hz)\n",
      "- Filter length: 413 samples (1.652 s)\n",
      "\n",
      "Not setting metadata\n",
      "288 matching events found\n",
      "Setting baseline interval to [-0.3, 0.0] s\n",
      "Applying baseline correction (mode: mean)\n",
      "0 projection items activated\n",
      "Using data from preloaded Raw for 288 events and 1076 original time points ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  17 tasks      | elapsed:    0.2s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 bad epochs dropped\n"
     ]
    }
   ],
   "source": [
    "# passbands = [\n",
    "#     (1, 3), (2, 5), (4, 7), (6, 10), (7, 12),\n",
    "#     (10, 15), (12, 19), (15, 25), (19, 30),\n",
    "#     (25, 35), (30, 40)\n",
    "# ]\n",
    "# Testing 1 band at a time\n",
    "passbands = [\n",
    "    (2, 5)\n",
    "]\n",
    "\n",
    "n_bands = 1\n",
    "\n",
    "gdf_folder = Path(\"BCICIV_2a_gdf\")\n",
    "\n",
    "target_events = {'769': 'left', '770': 'right', '771': 'feet', '772': 'tongue'}\n",
    "\n",
    "filtered_data = []\n",
    "labels_2d = []\n",
    "\n",
    "# skipping AO4T because only has eye movement\n",
    "users = [\"A01T.gdf\", \"A02T.gdf\", \"A03T.gdf\", \"A05T.gdf\", \"A06T.gdf\", \"A07T.gdf\", \"A08T.gdf\", \"A09T.gdf\"]\n",
    "\n",
    "for subject in users:\n",
    "    # Iterate through users\n",
    "    gdf_path = gdf_folder / subject\n",
    "    print(f\"\\nProcessing {subject}...\")\n",
    "    \n",
    "    raw = mne.io.read_raw_gdf(gdf_path.resolve(), preload=True)\n",
    "    events, event_id_map = mne.events_from_annotations(raw)\n",
    "\n",
    "    subject_data = []\n",
    "    user_labels = []\n",
    "\n",
    "    user_event_ids = {target_events[key]: event_id_map[key] for key in target_events if key in event_id_map}\n",
    "\n",
    "    # Filter and epoch for each band\n",
    "    for band in passbands:\n",
    "        low, high = band\n",
    "        print(f\"  Filtering {low}-{high} Hz...\")\n",
    "\n",
    "        # Bandpass filter\n",
    "        raw_filtered = raw.copy().filter(l_freq=low, h_freq=high, method='fir', fir_design='firwin')\n",
    "\n",
    "        # Create epochs\n",
    "        epochs = mne.Epochs(raw_filtered, events, event_id=user_event_ids, baseline=(None, 0), event_repeated='merge', preload=True, tmin=-.3, tmax=4)\n",
    "        labels = epochs.events[:, -1]  # Last column contains the event ID\n",
    "\n",
    "        # Collect data and labels\n",
    "        subject_data.append(epochs.get_data()[:, :-3, :])  # Shape: (n_trials, n_channels, n_times)\n",
    "        user_labels.append(labels)\n",
    "\n",
    "    filtered_data.append(subject_data)\n",
    "    labels_2d.append(user_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Separating data into 4 groups**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((8, 1, 72, 22, 1076),\n",
       " (8, 1, 72, 22, 1076),\n",
       " (8, 1, 72, 22, 1076),\n",
       " (8, 1, 72, 22, 1076))"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_left = []\n",
    "data_right = []\n",
    "data_feet = []\n",
    "data_tongue = []\n",
    "\n",
    "for subject in range(len(filtered_data)):\n",
    "    subject_data_left = []\n",
    "    subject_data_right = []\n",
    "    subject_data_feet = []\n",
    "    subject_data_tongue = []\n",
    "    for band in range(len(filtered_data[subject])):\n",
    "        band_data_left = []\n",
    "        band_data_right = []\n",
    "        band_data_feet = []\n",
    "        band_data_tongue = []\n",
    "        for label in range(len(labels_2d[subject][band])):\n",
    "            if labels_2d[subject][band][label] == 7:\n",
    "                band_data_left.append(filtered_data[subject][band][label])\n",
    "            elif labels_2d[subject][band][label] == 8:\n",
    "                band_data_right.append(filtered_data[subject][band][label])\n",
    "            elif labels_2d[subject][band][label] == 9:\n",
    "                band_data_feet.append(filtered_data[subject][band][label])\n",
    "            else:\n",
    "                band_data_tongue.append(filtered_data[subject][band][label])\n",
    "        subject_data_left.append(band_data_left)\n",
    "        subject_data_right.append(band_data_right)\n",
    "        subject_data_feet.append(band_data_feet)\n",
    "        subject_data_tongue.append(band_data_tongue)\n",
    "    data_left.append(subject_data_left)\n",
    "    data_right.append(subject_data_right)\n",
    "    data_feet.append(subject_data_feet)\n",
    "    data_tongue.append(subject_data_tongue)\n",
    "\n",
    "data_left = np.array(data_left)\n",
    "data_right = np.array(data_right)\n",
    "data_feet = np.array(data_feet)\n",
    "data_tongue = np.array(data_tongue)\n",
    "\n",
    "data_left.shape, data_right.shape, data_feet.shape, data_tongue.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_OVR_left = []\n",
    "data_OVR_right = []\n",
    "data_OVR_feet = []\n",
    "data_OVR_tongue = []\n",
    "\n",
    "random_samples = np.random.permutation(72)\n",
    "random_sample_range1 = random_samples[:24]\n",
    "random_sample_range2 = random_samples[24:48]\n",
    "random_sample_range3 = random_samples[48:72]\n",
    "\n",
    "# data_OVR_left\n",
    "for subject in range(8):\n",
    "    subject_data = []\n",
    "    for band in range(n_bands):\n",
    "        band_data = []\n",
    "        for sample in random_sample_range1:\n",
    "            band_data.append(data_right[subject][band][sample])\n",
    "        for sample in random_sample_range2:\n",
    "            band_data.append(data_feet[subject][band][sample])\n",
    "        for sample in random_sample_range3:\n",
    "            band_data.append(data_tongue[subject][band][sample])\n",
    "        np.random.shuffle(band_data)\n",
    "        subject_data.append(band_data)\n",
    "    data_OVR_left.append(subject_data)\n",
    "\n",
    "# data_OVR_right\n",
    "for subject in range(8):\n",
    "    subject_data = []\n",
    "    for band in range(n_bands):\n",
    "        band_data = []\n",
    "        for sample in random_sample_range1:\n",
    "            band_data.append(data_left[subject][band][sample])\n",
    "        for sample in random_sample_range2:\n",
    "            band_data.append(data_feet[subject][band][sample])\n",
    "        for sample in random_sample_range3:\n",
    "            band_data.append(data_tongue[subject][band][sample])\n",
    "        np.random.shuffle(band_data)\n",
    "        subject_data.append(band_data)\n",
    "    data_OVR_right.append(subject_data)\n",
    "\n",
    "# data_OVR_feet\n",
    "for subject in range(8):\n",
    "    subject_data = []\n",
    "    for band in range(n_bands):\n",
    "        band_data = []\n",
    "        for sample in random_sample_range1:\n",
    "            band_data.append(data_left[subject][band][sample])\n",
    "        for sample in random_sample_range2:\n",
    "            band_data.append(data_right[subject][band][sample])\n",
    "        for sample in random_sample_range3:\n",
    "            band_data.append(data_tongue[subject][band][sample])\n",
    "        np.random.shuffle(band_data)\n",
    "        subject_data.append(band_data)\n",
    "    data_OVR_feet.append(subject_data)\n",
    "\n",
    "# data_OVR_tongue\n",
    "for subject in range(8):\n",
    "    subject_data = []\n",
    "    for band in range(n_bands):\n",
    "        band_data = []\n",
    "        for sample in random_sample_range1:\n",
    "            band_data.append(data_left[subject][band][sample])\n",
    "        for sample in random_sample_range2:\n",
    "            band_data.append(data_right[subject][band][sample])\n",
    "        for sample in random_sample_range3:\n",
    "            band_data.append(data_feet[subject][band][sample])\n",
    "        np.random.shuffle(band_data)\n",
    "        subject_data.append(band_data)\n",
    "    data_OVR_tongue.append(subject_data)\n",
    "\n",
    "# Convert to numpy arrays\n",
    "data_OVR_left = np.array(data_OVR_left)\n",
    "data_OVR_right = np.array(data_OVR_right)\n",
    "data_OVR_feet = np.array(data_OVR_feet)\n",
    "data_OVR_tongue = np.array(data_OVR_tongue)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((8, 1, 22, 1076, 72),\n",
       " (8, 1, 22, 1076, 72),\n",
       " (8, 1, 22, 1076, 72),\n",
       " (8, 1, 22, 1076, 72))"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# # Reordering dimensions\n",
    "data_left = data_left.transpose(0, 1, 3, 4, 2)\n",
    "data_right = data_right.transpose(0, 1, 3, 4, 2)\n",
    "data_feet = data_feet.transpose(0, 1, 3, 4, 2)\n",
    "data_tongue = data_tongue.transpose(0, 1, 3, 4, 2)\n",
    "\n",
    "data_left.shape, data_right.shape, data_feet.shape, data_tongue.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((8, 1, 22, 1076, 72),\n",
       " (8, 1, 22, 1076, 72),\n",
       " (8, 1, 22, 1076, 72),\n",
       " (8, 1, 22, 1076, 72))"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# # Reordering dimensions\n",
    "data_OVR_left = data_OVR_left.transpose(0, 1, 3, 4, 2)\n",
    "data_OVR_right = data_OVR_right.transpose(0, 1, 3, 4, 2)\n",
    "data_OVR_feet = data_OVR_feet.transpose(0, 1, 3, 4, 2)\n",
    "data_OVR_tongue = data_OVR_tongue.transpose(0, 1, 3, 4, 2)\n",
    "\n",
    "data_OVR_left.shape, data_OVR_right.shape, data_OVR_feet.shape, data_OVR_tongue.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from mne.decoding import CSP\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis as LDA\n",
    "from sklearn.pipeline import make_pipeline\n",
    "\n",
    "import moabb\n",
    "from moabb.datasets import BNCI2014_001\n",
    "from moabb.evaluations import WithinSessionEvaluation\n",
    "from moabb.paradigms import LeftRightImagery\n",
    "\n",
    "\n",
    "moabb.set_log_level(\"info\")\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "dataset = BNCI2014_001()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "sessions = dataset.get_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Subject:  1\n",
      "Subject:  2\n",
      "Subject:  3\n",
      "Subject:  4\n",
      "Subject:  5\n",
      "Subject:  6\n",
      "Subject:  7\n",
      "Subject:  8\n",
      "Subject:  9\n"
     ]
    }
   ],
   "source": [
    "# passbands = [\n",
    "#     (1, 3), (2, 5), (4, 7), (6, 10), (7, 12),\n",
    "#     (10, 15), (12, 19), (15, 25), (19, 30),\n",
    "#     (25, 35), (30, 40)\n",
    "# ]\n",
    "\n",
    "filtered_data = []\n",
    "labels_2d = []\n",
    "\n",
    "# skipping AO4T because only has eye movement\n",
    "runs = [\"0\", \"1\", \"2\", \"3\", \"4\", \"5\"]\n",
    "\n",
    "skip = 4\n",
    "\n",
    "for subject in range(1, 10):\n",
    "    print(\"Subject: \", subject)\n",
    "    if subject == skip:\n",
    "        continue\n",
    "\n",
    "    # List to store all raw objects\n",
    "    raw_list = []\n",
    "    \n",
    "    # Iterate over runs and add each raw to the list\n",
    "    for run in runs:\n",
    "        raw = sessions[subject][\"1test\"][run]\n",
    "        raw_list.append(raw)\n",
    "    \n",
    "    # Concatenate all raw objects into one\n",
    "    combined_raw = mne.concatenate_raws(raw_list)\n",
    "    \n",
    "    # Iterate through users\n",
    "    \n",
    "    raw = combined_raw\n",
    "    events, event_id = mne.events_from_annotations(raw)\n",
    "\n",
    "    subject_data = []\n",
    "    user_labels = []\n",
    "\n",
    "    # Filter and epoch for each band\n",
    "    for band in passbands:\n",
    "        low, high = band\n",
    "\n",
    "        # Bandpass filter\n",
    "        raw_filtered = raw.copy().filter(l_freq=low, h_freq=high, method='fir', fir_design='firwin')\n",
    "\n",
    "        # Create epochs\n",
    "        epochs = mne.Epochs(raw_filtered, events, event_id=event_id, baseline=(None, 0), event_repeated='merge', preload=True, tmin=-.3, tmax=4)\n",
    "        labels = epochs.events[:, -1]  # Last column contains the event ID\n",
    "\n",
    "        # Collect data and labels\n",
    "        subject_data.append(epochs.get_data()[:, :-4, :])  # Shape: (n_trials, n_channels, n_times)\n",
    "        user_labels.append(labels)\n",
    "    filtered_data.append(subject_data)\n",
    "    labels_2d.append(user_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((8, 1, 72, 22, 1076),\n",
       " (8, 1, 72, 22, 1076),\n",
       " (8, 1, 72, 22, 1076),\n",
       " (8, 1, 72, 22, 1076))"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data_left = []\n",
    "test_data_right = []\n",
    "test_data_feet = []\n",
    "test_data_tongue = []\n",
    "\n",
    "for subject in range(len(filtered_data)):\n",
    "    subject_data_left = []\n",
    "    subject_data_right = []\n",
    "    subject_data_feet = []\n",
    "    subject_data_tongue = []\n",
    "    for band in range(len(filtered_data[subject])):\n",
    "        band_data_left = []\n",
    "        band_data_right = []\n",
    "        band_data_feet = []\n",
    "        band_data_tongue = []\n",
    "        for label in range(len(labels_2d[subject][band])):\n",
    "            if labels_2d[subject][band][label] == 2:\n",
    "                band_data_left.append(filtered_data[subject][band][label])\n",
    "            elif labels_2d[subject][band][label] == 3:\n",
    "                band_data_right.append(filtered_data[subject][band][label])\n",
    "            elif labels_2d[subject][band][label] == 1:\n",
    "                band_data_feet.append(filtered_data[subject][band][label])\n",
    "            else:\n",
    "                band_data_tongue.append(filtered_data[subject][band][label])\n",
    "        subject_data_left.append(band_data_left)\n",
    "        subject_data_right.append(band_data_right)\n",
    "        subject_data_feet.append(band_data_feet)\n",
    "        subject_data_tongue.append(band_data_tongue)\n",
    "    test_data_left.append(subject_data_left)\n",
    "    test_data_right.append(subject_data_right)\n",
    "    test_data_feet.append(subject_data_feet)\n",
    "    test_data_tongue.append(subject_data_tongue)\n",
    "\n",
    "test_data_left = np.array(test_data_left)\n",
    "test_data_right = np.array(test_data_right)\n",
    "test_data_feet = np.array(test_data_feet)\n",
    "test_data_tongue = np.array(test_data_tongue)\n",
    "\n",
    "test_data_left.shape, test_data_right.shape, test_data_feet.shape, test_data_tongue.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data_OVR_left = []\n",
    "test_data_OVR_right = []\n",
    "test_data_OVR_feet = []\n",
    "test_data_OVR_tongue = []\n",
    "\n",
    "random_samples = np.random.permutation(72)\n",
    "random_sample_range1 = random_samples[:24]\n",
    "random_sample_range2 = random_samples[24:48]\n",
    "random_sample_range3 = random_samples[48:72]\n",
    "\n",
    "# data_OVR_left\n",
    "for subject in range(8):\n",
    "    subject_data = []\n",
    "    for band in range(n_bands):\n",
    "        band_data = []\n",
    "        for sample in random_sample_range1:\n",
    "            band_data.append(test_data_right[subject][band][sample])\n",
    "        for sample in random_sample_range2:\n",
    "            band_data.append(test_data_feet[subject][band][sample])\n",
    "        for sample in random_sample_range3:\n",
    "            band_data.append(test_data_tongue[subject][band][sample])\n",
    "        np.random.shuffle(band_data)\n",
    "        subject_data.append(band_data)\n",
    "    test_data_OVR_left.append(subject_data)\n",
    "\n",
    "# data_OVR_right\n",
    "for subject in range(8):\n",
    "    subject_data = []\n",
    "    for band in range(n_bands):\n",
    "        band_data = []\n",
    "        for sample in random_sample_range1:\n",
    "            band_data.append(test_data_left[subject][band][sample])\n",
    "        for sample in random_sample_range2:\n",
    "            band_data.append(test_data_feet[subject][band][sample])\n",
    "        for sample in random_sample_range3:\n",
    "            band_data.append(test_data_tongue[subject][band][sample])\n",
    "        np.random.shuffle(band_data)\n",
    "        subject_data.append(band_data)\n",
    "    test_data_OVR_right.append(subject_data)\n",
    "\n",
    "# data_OVR_feet\n",
    "for subject in range(8):\n",
    "    subject_data = []\n",
    "    for band in range(n_bands):\n",
    "        band_data = []\n",
    "        for sample in random_sample_range1:\n",
    "            band_data.append(test_data_left[subject][band][sample])\n",
    "        for sample in random_sample_range2:\n",
    "            band_data.append(test_data_right[subject][band][sample])\n",
    "        for sample in random_sample_range3:\n",
    "            band_data.append(test_data_tongue[subject][band][sample])\n",
    "        np.random.shuffle(band_data)\n",
    "        subject_data.append(band_data)\n",
    "    test_data_OVR_feet.append(subject_data)\n",
    "\n",
    "# data_OVR_tongue\n",
    "for subject in range(8):\n",
    "    subject_data = []\n",
    "    for band in range(n_bands):\n",
    "        band_data = []\n",
    "        for sample in random_sample_range1:\n",
    "            band_data.append(test_data_left[subject][band][sample])\n",
    "        for sample in random_sample_range2:\n",
    "            band_data.append(test_data_right[subject][band][sample])\n",
    "        for sample in random_sample_range3:\n",
    "            band_data.append(test_data_feet[subject][band][sample])\n",
    "        np.random.shuffle(band_data)\n",
    "        subject_data.append(band_data)\n",
    "    test_data_OVR_tongue.append(subject_data)\n",
    "\n",
    "# Convert to numpy arrays\n",
    "test_data_OVR_left = np.array(test_data_OVR_left)\n",
    "test_data_OVR_right = np.array(test_data_OVR_right)\n",
    "test_data_OVR_feet = np.array(test_data_OVR_feet)\n",
    "test_data_OVR_tongue = np.array(test_data_OVR_tongue)\n",
    "\n",
    "test_data_OVR_left = test_data_OVR_left.transpose(0, 1, 3, 4, 2)\n",
    "test_data_OVR_right = test_data_OVR_right.transpose(0, 1, 3, 4, 2)\n",
    "test_data_OVR_feet = test_data_OVR_feet.transpose(0, 1, 3, 4, 2)\n",
    "test_data_OVR_tongue = test_data_OVR_tongue.transpose(0, 1, 3, 4, 2)\n",
    "\n",
    "test_data_left = test_data_left.transpose(0, 1, 3, 4, 2)\n",
    "test_data_right = test_data_right.transpose(0, 1, 3, 4, 2)\n",
    "test_data_feet = test_data_feet.transpose(0, 1, 3, 4, 2)\n",
    "test_data_tongue = test_data_tongue.transpose(0, 1, 3, 4, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8, 1, 22, 1076, 72)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data_left.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Left vs Rest - Test Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===============\n",
      "Processing Subject 1/8\n",
      "Processing Fold 1/6\n",
      "Processing Fold 2/6\n",
      "Processing Fold 3/6\n",
      "Processing Fold 4/6\n",
      "Processing Fold 5/6\n",
      "Processing Fold 6/6\n",
      "===============\n",
      "Processing Subject 2/8\n",
      "Processing Fold 1/6\n",
      "Processing Fold 2/6\n",
      "Processing Fold 3/6\n",
      "Processing Fold 4/6\n",
      "Processing Fold 5/6\n",
      "Processing Fold 6/6\n",
      "===============\n",
      "Processing Subject 3/8\n",
      "Processing Fold 1/6\n",
      "Processing Fold 2/6\n",
      "Processing Fold 3/6\n",
      "Processing Fold 4/6\n",
      "Processing Fold 5/6\n",
      "Processing Fold 6/6\n",
      "===============\n",
      "Processing Subject 4/8\n",
      "Processing Fold 1/6\n",
      "Processing Fold 2/6\n",
      "Processing Fold 3/6\n",
      "Processing Fold 4/6\n",
      "Processing Fold 5/6\n",
      "Processing Fold 6/6\n",
      "===============\n",
      "Processing Subject 5/8\n",
      "Processing Fold 1/6\n",
      "Processing Fold 2/6\n",
      "Processing Fold 3/6\n",
      "Processing Fold 4/6\n",
      "Processing Fold 5/6\n",
      "Processing Fold 6/6\n",
      "===============\n",
      "Processing Subject 6/8\n",
      "Processing Fold 1/6\n",
      "Processing Fold 2/6\n",
      "Processing Fold 3/6\n",
      "Processing Fold 4/6\n",
      "Processing Fold 5/6\n",
      "Processing Fold 6/6\n",
      "===============\n",
      "Processing Subject 7/8\n",
      "Processing Fold 1/6\n",
      "Processing Fold 2/6\n",
      "Processing Fold 3/6\n",
      "Processing Fold 4/6\n",
      "Processing Fold 5/6\n",
      "Processing Fold 6/6\n",
      "===============\n",
      "Processing Subject 8/8\n",
      "Processing Fold 1/6\n",
      "Processing Fold 2/6\n",
      "Processing Fold 3/6\n",
      "Processing Fold 4/6\n",
      "Processing Fold 5/6\n",
      "Processing Fold 6/6\n",
      "===============\n",
      "[0.59722222 0.53009259 0.64583333 0.59375    0.49305556 0.7962963\n",
      " 0.67476852 0.75347222]\n",
      "[ 0.19444444  0.06018519  0.29166667  0.1875     -0.01388889  0.59259259\n",
      "  0.34953704  0.50694444]\n"
     ]
    }
   ],
   "source": [
    "# We'll reset trainIdx and valIdx (just in case)\n",
    "# Note: feel free to use uninitialized lists and append\n",
    "#       this is just one possible starting point to show\n",
    "#       the correct size of these objects.\n",
    "trainIdx = np.zeros((k, bin_size*(k-1)), dtype=int) # could also be = []\n",
    "valIdx = np.zeros((k, bin_size), dtype=int)           # could also be = []\n",
    "\n",
    "# --- Question 4 ---\n",
    "# YOUR CODE HERE\n",
    "\n",
    "for i in range(k):\n",
    "    lst = []\n",
    "    for row in range(k):\n",
    "        if row == 0:\n",
    "            valIdx[i] = randIdx[row]\n",
    "            continue\n",
    "        for col in range(len(randIdx[0])):\n",
    "            lst.append(randIdx[row][col])\n",
    "    trainIdx[i] = lst\n",
    "    randIdx = np.random.permutation(n_sample)\n",
    "    randIdx = randIdx.reshape(k, bin_size)\n",
    "valIdx\n",
    "\n",
    "assert valIdx.shape == (k, bin_size)\n",
    "assert trainIdx.shape == (k, bin_size*(k-1))\n",
    "\n",
    "# Main Analysis (Do Not Modify)\n",
    "\n",
    "# Declare useful variables\n",
    "n_subjects, n_filters = (8, 1)\n",
    "train_size = bin_size * (k-1)\n",
    "val_size = bin_size\n",
    "test_size = 72\n",
    "accuracy = np.zeros((n_subjects, k))\n",
    "kappa = np.zeros((n_subjects, k))\n",
    "csp_per_class = 3\n",
    "trainIdx = trainIdx.astype(int)\n",
    "valIdx = valIdx.astype(int)\n",
    "lvr = []\n",
    "\n",
    "# Begin nested loops\n",
    "# Subject > Fold > Band\n",
    "print('===============')\n",
    "for subject in range(8):\n",
    "    print('Processing Subject {}/{}'.format(subject+1, n_subjects))\n",
    "    for fold in range(k):\n",
    "        print('Processing Fold {}/{}'.format(fold+1, k))\n",
    "        band_score_train = np.zeros((train_size*2, n_filters))\n",
    "        band_score_val = np.zeros((val_size*2, n_filters))\n",
    "        band_score_test = np.zeros((test_size*2, n_filters))\n",
    "        for band in range(n_filters):\n",
    "            # train,val dataset -> train,val for each subject&band\n",
    "            l_train = data_left[subject, band][:,:,trainIdx[fold]].transpose(2,0,1) # (trials, chans, samples)\n",
    "            OVR_train = data_OVR_left[subject, band][:,:,trainIdx[fold]].transpose(2,0,1) # (trials, chans, samples)\n",
    "            l_val = data_left[subject, band][:,:,valIdx[fold]].transpose(2,0,1) # (trials, chans, samples)\n",
    "            OVR_val = data_OVR_left[subject, band][:,:,valIdx[fold]].transpose(2,0,1) # (trials, chans, samples)\n",
    "            l_test = test_data_left[subject, band][:,:,:].transpose(2,0,1) # (trials, chans, samples)\n",
    "            OVR_test = test_data_OVR_left[subject, band][:,:,:].transpose(2,0,1) # (trials, chans, samples)\n",
    "            train_data = np.stack((l_train,OVR_train), axis=0) # <- CSP input data format (classes, trials, chans, samples) \n",
    "            val_data = np.stack((l_val,OVR_val), axis=0) # <- CSP input data format (classes, trials, chans, samples)\n",
    "            test_data = np.stack((l_test,OVR_test), axis=0) # <- CSP input data format (classes, trials, chans, samples)\n",
    "\n",
    "\n",
    "            # Run Mahta's CSP code\n",
    "            # Source: https://github.com/mahtamsv/CCACSP\n",
    "            csp_filts, clf = train(train_data[0], train_data[1], csp_per_class)\n",
    "            train_prob = test(np.vstack(train_data), csp_filts, clf)\n",
    "            val_prob = test(np.vstack(val_data), csp_filts, clf)\n",
    "            test_prob = test(np.vstack(test_data), csp_filts, clf)\n",
    "            \n",
    "            # test() gives the prob of the 0th class, that's why \n",
    "            # we have y_val seemingly switched below\n",
    "            y_val = np.append(np.ones(12), np.zeros(12))\n",
    "            y_true = np.append(np.ones(72), np.zeros(72))\n",
    "\n",
    "            band_score_train[:,band] = train_prob\n",
    "            band_score_val[:,band] = val_prob\n",
    "            band_score_test[:,band] = test_prob\n",
    "\n",
    "        \n",
    "        \n",
    "        y_pred = np.rint(band_score_test.mean(1))\n",
    "        accuracy[subject,fold] = sum(y_pred==y_true)/len(y_true)\n",
    "        kappa[subject, fold] = cohen_kappa_score(y_pred, y_true)\n",
    "    print('===============')\n",
    "print(np.mean(accuracy, axis=1))\n",
    "print(np.mean(kappa, axis=1))\n",
    "lvo = np.mean(kappa, axis=1).tolist()\n",
    "\n",
    "# Main Analysis Over"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Right vs Rest - Test Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===============\n",
      "Processing Subject 1/8\n",
      "Processing Fold 1/6\n",
      "Processing Fold 2/6\n",
      "Processing Fold 3/6\n",
      "Processing Fold 4/6\n",
      "Processing Fold 5/6\n",
      "Processing Fold 6/6\n",
      "===============\n",
      "Processing Subject 2/8\n",
      "Processing Fold 1/6\n",
      "Processing Fold 2/6\n",
      "Processing Fold 3/6\n",
      "Processing Fold 4/6\n",
      "Processing Fold 5/6\n",
      "Processing Fold 6/6\n",
      "===============\n",
      "Processing Subject 3/8\n",
      "Processing Fold 1/6\n",
      "Processing Fold 2/6\n",
      "Processing Fold 3/6\n",
      "Processing Fold 4/6\n",
      "Processing Fold 5/6\n",
      "Processing Fold 6/6\n",
      "===============\n",
      "Processing Subject 4/8\n",
      "Processing Fold 1/6\n",
      "Processing Fold 2/6\n",
      "Processing Fold 3/6\n",
      "Processing Fold 4/6\n",
      "Processing Fold 5/6\n",
      "Processing Fold 6/6\n",
      "===============\n",
      "Processing Subject 5/8\n",
      "Processing Fold 1/6\n",
      "Processing Fold 2/6\n",
      "Processing Fold 3/6\n",
      "Processing Fold 4/6\n",
      "Processing Fold 5/6\n",
      "Processing Fold 6/6\n",
      "===============\n",
      "Processing Subject 6/8\n",
      "Processing Fold 1/6\n",
      "Processing Fold 2/6\n",
      "Processing Fold 3/6\n",
      "Processing Fold 4/6\n",
      "Processing Fold 5/6\n",
      "Processing Fold 6/6\n",
      "===============\n",
      "Processing Subject 7/8\n",
      "Processing Fold 1/6\n",
      "Processing Fold 2/6\n",
      "Processing Fold 3/6\n",
      "Processing Fold 4/6\n",
      "Processing Fold 5/6\n",
      "Processing Fold 6/6\n",
      "===============\n",
      "Processing Subject 8/8\n",
      "Processing Fold 1/6\n",
      "Processing Fold 2/6\n",
      "Processing Fold 3/6\n",
      "Processing Fold 4/6\n",
      "Processing Fold 5/6\n",
      "Processing Fold 6/6\n",
      "===============\n",
      "[0.63541667 0.5162037  0.54166667 0.49768519 0.5150463  0.67708333\n",
      " 0.56712963 0.55324074]\n",
      "[ 0.27083333  0.03240741  0.08333333 -0.00462963  0.03009259  0.35416667\n",
      "  0.13425926  0.10648148]\n"
     ]
    }
   ],
   "source": [
    "# We'll reset trainIdx and valIdx (just in case)\n",
    "# Note: feel free to use uninitialized lists and append\n",
    "#       this is just one possible starting point to show\n",
    "#       the correct size of these objects.\n",
    "trainIdx = np.zeros((k, bin_size*(k-1)), dtype=int) # could also be = []\n",
    "valIdx = np.zeros((k, bin_size), dtype=int)           # could also be = []\n",
    "\n",
    "# --- Question 4 ---\n",
    "# YOUR CODE HERE\n",
    "\n",
    "for i in range(k):\n",
    "    lst = []\n",
    "    for row in range(k):\n",
    "        if row == 0:\n",
    "            valIdx[i] = randIdx[row]\n",
    "            continue\n",
    "        for col in range(len(randIdx[0])):\n",
    "            lst.append(randIdx[row][col])\n",
    "    trainIdx[i] = lst\n",
    "    randIdx = np.random.permutation(n_sample)\n",
    "    randIdx = randIdx.reshape(k, bin_size)\n",
    "valIdx\n",
    "\n",
    "assert valIdx.shape == (k, bin_size)\n",
    "assert trainIdx.shape == (k, bin_size*(k-1))\n",
    "\n",
    "# Main Analysis (Do Not Modify)\n",
    "\n",
    "# Declare useful variables\n",
    "n_subjects, n_filters = (8, 1)\n",
    "train_size = bin_size * (k-1)\n",
    "val_size = bin_size\n",
    "test_size = 72\n",
    "accuracy = np.zeros((n_subjects, k))\n",
    "kappa = np.zeros((n_subjects, k))\n",
    "csp_per_class = 3\n",
    "trainIdx = trainIdx.astype(int)\n",
    "valIdx = valIdx.astype(int)\n",
    "\n",
    "# Begin nested loops\n",
    "# Subject > Fold > Band\n",
    "print('===============')\n",
    "for subject in range(8):\n",
    "    print('Processing Subject {}/{}'.format(subject+1, n_subjects))\n",
    "    for fold in range(k):\n",
    "        print('Processing Fold {}/{}'.format(fold+1, k))\n",
    "        band_score_train = np.zeros((train_size*2, n_filters))\n",
    "        band_score_val = np.zeros((val_size*2, n_filters))\n",
    "        band_score_test = np.zeros((test_size*2, n_filters))\n",
    "        for band in range(n_filters):\n",
    "            # train,val dataset -> train,val for each subject&band\n",
    "            r_train = data_right[subject, band][:,:,trainIdx[fold]].transpose(2,0,1) # (trials, chans, samples)\n",
    "            OVR_train = data_OVR_right[subject, band][:,:,trainIdx[fold]].transpose(2,0,1) # (trials, chans, samples)\n",
    "            r_val = data_right[subject, band][:,:,valIdx[fold]].transpose(2,0,1) # (trials, chans, samples)\n",
    "            OVR_val = data_OVR_right[subject, band][:,:,valIdx[fold]].transpose(2,0,1) # (trials, chans, samples)\n",
    "            r_test = test_data_right[subject, band][:,:,:].transpose(2,0,1) # (trials, chans, samples)\n",
    "            OVR_test = test_data_OVR_right[subject, band][:,:,:].transpose(2,0,1) # (trials, chans, samples)\n",
    "            train_data = np.stack((r_train,OVR_train), axis=0) # <- CSP input data format (classes, trials, chans, samples) \n",
    "            val_data = np.stack((r_val,OVR_val), axis=0) # <- CSP input data format (classes, trials, chans, samples)\n",
    "            test_data = np.stack((r_test,OVR_test), axis=0) # <- CSP input data format (classes, trials, chans, samples)\n",
    "\n",
    "\n",
    "            # Run Mahta's CSP code\n",
    "            # Source: https://github.com/mahtamsv/CCACSP\n",
    "            csp_filts, clf = train(train_data[0], train_data[1], csp_per_class)\n",
    "            train_prob = test(np.vstack(train_data), csp_filts, clf)\n",
    "            val_prob = test(np.vstack(val_data), csp_filts, clf)\n",
    "            test_prob = test(np.vstack(test_data), csp_filts, clf)\n",
    "            \n",
    "            # test() gives the prob of the 0th class, that's why \n",
    "            # we have y_val seemingly switched below\n",
    "            y_val = np.append(np.ones(12), np.zeros(12))\n",
    "            y_true = np.append(np.ones(72), np.zeros(72))\n",
    "\n",
    "            band_score_train[:,band] = train_prob\n",
    "            band_score_val[:,band] = val_prob\n",
    "            band_score_test[:,band] = test_prob\n",
    "\n",
    "        \n",
    "        \n",
    "        y_pred = np.rint(band_score_test.mean(1))\n",
    "        accuracy[subject,fold] = sum(y_pred==y_true)/len(y_true)\n",
    "        kappa[subject, fold] = cohen_kappa_score(y_pred, y_true)\n",
    "    print('===============')\n",
    "print(np.mean(accuracy, axis=1))\n",
    "print(np.mean(kappa, axis=1))\n",
    "rvo = np.mean(kappa, axis=1).tolist()\n",
    "\n",
    "# Main Analysis Over"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feet vs Rest - Test Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===============\n",
      "Processing Subject 1/8\n",
      "Processing Fold 1/6\n",
      "Processing Fold 2/6\n",
      "Processing Fold 3/6\n",
      "Processing Fold 4/6\n",
      "Processing Fold 5/6\n",
      "Processing Fold 6/6\n",
      "===============\n",
      "Processing Subject 2/8\n",
      "Processing Fold 1/6\n",
      "Processing Fold 2/6\n",
      "Processing Fold 3/6\n",
      "Processing Fold 4/6\n",
      "Processing Fold 5/6\n",
      "Processing Fold 6/6\n",
      "===============\n",
      "Processing Subject 3/8\n",
      "Processing Fold 1/6\n",
      "Processing Fold 2/6\n",
      "Processing Fold 3/6\n",
      "Processing Fold 4/6\n",
      "Processing Fold 5/6\n",
      "Processing Fold 6/6\n",
      "===============\n",
      "Processing Subject 4/8\n",
      "Processing Fold 1/6\n",
      "Processing Fold 2/6\n",
      "Processing Fold 3/6\n",
      "Processing Fold 4/6\n",
      "Processing Fold 5/6\n",
      "Processing Fold 6/6\n",
      "===============\n",
      "Processing Subject 5/8\n",
      "Processing Fold 1/6\n",
      "Processing Fold 2/6\n",
      "Processing Fold 3/6\n",
      "Processing Fold 4/6\n",
      "Processing Fold 5/6\n",
      "Processing Fold 6/6\n",
      "===============\n",
      "Processing Subject 6/8\n",
      "Processing Fold 1/6\n",
      "Processing Fold 2/6\n",
      "Processing Fold 3/6\n",
      "Processing Fold 4/6\n",
      "Processing Fold 5/6\n",
      "Processing Fold 6/6\n",
      "===============\n",
      "Processing Subject 7/8\n",
      "Processing Fold 1/6\n",
      "Processing Fold 2/6\n",
      "Processing Fold 3/6\n",
      "Processing Fold 4/6\n",
      "Processing Fold 5/6\n",
      "Processing Fold 6/6\n",
      "===============\n",
      "Processing Subject 8/8\n",
      "Processing Fold 1/6\n",
      "Processing Fold 2/6\n",
      "Processing Fold 3/6\n",
      "Processing Fold 4/6\n",
      "Processing Fold 5/6\n",
      "Processing Fold 6/6\n",
      "===============\n",
      "[0.57291667 0.54398148 0.6087963  0.53935185 0.51736111 0.67476852\n",
      " 0.59606481 0.52199074]\n",
      "[0.14583333 0.08796296 0.21759259 0.0787037  0.03472222 0.34953704\n",
      " 0.19212963 0.04398148]\n"
     ]
    }
   ],
   "source": [
    "# We'll reset trainIdx and valIdx (just in case)\n",
    "# Note: feel free to use uninitialized lists and append\n",
    "#       this is just one possible starting point to show\n",
    "#       the correct size of these objects.\n",
    "trainIdx = np.zeros((k, bin_size*(k-1)), dtype=int) # could also be = []\n",
    "valIdx = np.zeros((k, bin_size), dtype=int)           # could also be = []\n",
    "\n",
    "# --- Question 4 ---\n",
    "# YOUR CODE HERE\n",
    "\n",
    "for i in range(k):\n",
    "    lst = []\n",
    "    for row in range(k):\n",
    "        if row == 0:\n",
    "            valIdx[i] = randIdx[row]\n",
    "            continue\n",
    "        for col in range(len(randIdx[0])):\n",
    "            lst.append(randIdx[row][col])\n",
    "    trainIdx[i] = lst\n",
    "    randIdx = np.random.permutation(n_sample)\n",
    "    randIdx = randIdx.reshape(k, bin_size)\n",
    "valIdx\n",
    "\n",
    "assert valIdx.shape == (k, bin_size)\n",
    "assert trainIdx.shape == (k, bin_size*(k-1))\n",
    "\n",
    "# Main Analysis (Do Not Modify)\n",
    "\n",
    "# Declare useful variables\n",
    "n_subjects, n_filters = (8, 1)\n",
    "train_size = bin_size * (k-1)\n",
    "val_size = bin_size\n",
    "test_size = 72\n",
    "accuracy = np.zeros((n_subjects, k))\n",
    "kappa = np.zeros((n_subjects, k))\n",
    "csp_per_class = 3\n",
    "trainIdx = trainIdx.astype(int)\n",
    "valIdx = valIdx.astype(int)\n",
    "\n",
    "# Begin nested loops\n",
    "# Subject > Fold > Band\n",
    "print('===============')\n",
    "for subject in range(8):\n",
    "    print('Processing Subject {}/{}'.format(subject+1, n_subjects))\n",
    "    for fold in range(k):\n",
    "        print('Processing Fold {}/{}'.format(fold+1, k))\n",
    "        band_score_train = np.zeros((train_size*2, n_filters))\n",
    "        band_score_val = np.zeros((val_size*2, n_filters))\n",
    "        band_score_test = np.zeros((test_size*2, n_filters))\n",
    "        for band in range(n_filters):\n",
    "            # train,val dataset -> train,val for each subject&band\n",
    "            f_train = data_feet[subject, band][:,:,trainIdx[fold]].transpose(2,0,1) # (trials, chans, samples)\n",
    "            OVR_train = data_OVR_feet[subject, band][:,:,trainIdx[fold]].transpose(2,0,1) # (trials, chans, samples)\n",
    "            f_val = data_feet[subject, band][:,:,valIdx[fold]].transpose(2,0,1) # (trials, chans, samples)\n",
    "            OVR_val = data_OVR_feet[subject, band][:,:,valIdx[fold]].transpose(2,0,1) # (trials, chans, samples)\n",
    "            f_test = test_data_feet[subject, band][:,:,:].transpose(2,0,1) # (trials, chans, samples)\n",
    "            OVR_test = test_data_OVR_feet[subject, band][:,:,:].transpose(2,0,1) # (trials, chans, samples)\n",
    "            train_data = np.stack((f_train,OVR_train), axis=0) # <- CSP input data format (classes, trials, chans, samples) \n",
    "            val_data = np.stack((f_val,OVR_val), axis=0) # <- CSP input data format (classes, trials, chans, samples)\n",
    "            test_data = np.stack((f_test,OVR_test), axis=0) # <- CSP input data format (classes, trials, chans, samples)\n",
    "\n",
    "\n",
    "            # Run Mahta's CSP code\n",
    "            # Source: https://github.com/mahtamsv/CCACSP\n",
    "            csp_filts, clf = train(train_data[0], train_data[1], csp_per_class)\n",
    "            train_prob = test(np.vstack(train_data), csp_filts, clf)\n",
    "            val_prob = test(np.vstack(val_data), csp_filts, clf)\n",
    "            test_prob = test(np.vstack(test_data), csp_filts, clf)\n",
    "            \n",
    "            # test() gives the prob of the 0th class, that's why \n",
    "            # we have y_val seemingly switched below\n",
    "            y_val = np.append(np.ones(12), np.zeros(12))\n",
    "            y_true = np.append(np.ones(72), np.zeros(72))\n",
    "\n",
    "            band_score_train[:,band] = train_prob\n",
    "            band_score_val[:,band] = val_prob\n",
    "            band_score_test[:,band] = test_prob\n",
    "\n",
    "        \n",
    "        \n",
    "        y_pred = np.rint(band_score_test.mean(1))\n",
    "        accuracy[subject,fold] = sum(y_pred==y_true)/len(y_true)\n",
    "        kappa[subject, fold] = cohen_kappa_score(y_pred, y_true)\n",
    "    print('===============')\n",
    "print(np.mean(accuracy, axis=1))\n",
    "print(np.mean(kappa, axis=1))\n",
    "fvo = np.mean(kappa, axis=1).tolist()\n",
    "\n",
    "# Main Analysis Over"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tongue vs Rest - Test Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===============\n",
      "Processing Subject 1/8\n",
      "Processing Fold 1/6\n",
      "Processing Fold 2/6\n",
      "Processing Fold 3/6\n",
      "Processing Fold 4/6\n",
      "Processing Fold 5/6\n",
      "Processing Fold 6/6\n",
      "===============\n",
      "Processing Subject 2/8\n",
      "Processing Fold 1/6\n",
      "Processing Fold 2/6\n",
      "Processing Fold 3/6\n",
      "Processing Fold 4/6\n",
      "Processing Fold 5/6\n",
      "Processing Fold 6/6\n",
      "===============\n",
      "Processing Subject 3/8\n",
      "Processing Fold 1/6\n",
      "Processing Fold 2/6\n",
      "Processing Fold 3/6\n",
      "Processing Fold 4/6\n",
      "Processing Fold 5/6\n",
      "Processing Fold 6/6\n",
      "===============\n",
      "Processing Subject 4/8\n",
      "Processing Fold 1/6\n",
      "Processing Fold 2/6\n",
      "Processing Fold 3/6\n",
      "Processing Fold 4/6\n",
      "Processing Fold 5/6\n",
      "Processing Fold 6/6\n",
      "===============\n",
      "Processing Subject 5/8\n",
      "Processing Fold 1/6\n",
      "Processing Fold 2/6\n",
      "Processing Fold 3/6\n",
      "Processing Fold 4/6\n",
      "Processing Fold 5/6\n",
      "Processing Fold 6/6\n",
      "===============\n",
      "Processing Subject 6/8\n",
      "Processing Fold 1/6\n",
      "Processing Fold 2/6\n",
      "Processing Fold 3/6\n",
      "Processing Fold 4/6\n",
      "Processing Fold 5/6\n",
      "Processing Fold 6/6\n",
      "===============\n",
      "Processing Subject 7/8\n",
      "Processing Fold 1/6\n",
      "Processing Fold 2/6\n",
      "Processing Fold 3/6\n",
      "Processing Fold 4/6\n",
      "Processing Fold 5/6\n",
      "Processing Fold 6/6\n",
      "===============\n",
      "Processing Subject 8/8\n",
      "Processing Fold 1/6\n",
      "Processing Fold 2/6\n",
      "Processing Fold 3/6\n",
      "Processing Fold 4/6\n",
      "Processing Fold 5/6\n",
      "Processing Fold 6/6\n",
      "===============\n",
      "[0.62152778 0.59837963 0.70949074 0.54282407 0.5150463  0.65740741\n",
      " 0.68402778 0.67013889]\n",
      "[0.24305556 0.19675926 0.41898148 0.08564815 0.03009259 0.31481481\n",
      " 0.36805556 0.34027778]\n"
     ]
    }
   ],
   "source": [
    "# We'll reset trainIdx and valIdx (just in case)\n",
    "# Note: feel free to use uninitialized lists and append\n",
    "#       this is just one possible starting point to show\n",
    "#       the correct size of these objects.\n",
    "trainIdx = np.zeros((k, bin_size*(k-1)), dtype=int) # could also be = []\n",
    "valIdx = np.zeros((k, bin_size), dtype=int)           # could also be = []\n",
    "\n",
    "# --- Question 4 ---\n",
    "# YOUR CODE HERE\n",
    "\n",
    "for i in range(k):\n",
    "    lst = []\n",
    "    for row in range(k):\n",
    "        if row == 0:\n",
    "            valIdx[i] = randIdx[row]\n",
    "            continue\n",
    "        for col in range(len(randIdx[0])):\n",
    "            lst.append(randIdx[row][col])\n",
    "    trainIdx[i] = lst\n",
    "    randIdx = np.random.permutation(n_sample)\n",
    "    randIdx = randIdx.reshape(k, bin_size)\n",
    "valIdx\n",
    "\n",
    "assert valIdx.shape == (k, bin_size)\n",
    "assert trainIdx.shape == (k, bin_size*(k-1))\n",
    "\n",
    "# Main Analysis (Do Not Modify)\n",
    "\n",
    "# Declare useful variables\n",
    "n_subjects, n_filters = (8, 1)\n",
    "train_size = bin_size * (k-1)\n",
    "val_size = bin_size\n",
    "test_size = 72\n",
    "accuracy = np.zeros((n_subjects, k))\n",
    "kappa = np.zeros((n_subjects, k))\n",
    "csp_per_class = 3\n",
    "trainIdx = trainIdx.astype(int)\n",
    "valIdx = valIdx.astype(int)\n",
    "\n",
    "# Begin nested loops\n",
    "# Subject > Fold > Band\n",
    "print('===============')\n",
    "for subject in range(8):\n",
    "    print('Processing Subject {}/{}'.format(subject+1, n_subjects))\n",
    "    for fold in range(k):\n",
    "        print('Processing Fold {}/{}'.format(fold+1, k))\n",
    "        band_score_train = np.zeros((train_size*2, n_filters))\n",
    "        band_score_val = np.zeros((val_size*2, n_filters))\n",
    "        band_score_test = np.zeros((test_size*2, n_filters))\n",
    "        for band in range(n_filters):\n",
    "            # train,val dataset -> train,val for each subject&band\n",
    "            t_train = data_tongue[subject, band][:,:,trainIdx[fold]].transpose(2,0,1) # (trials, chans, samples)\n",
    "            OVR_train = data_OVR_tongue[subject, band][:,:,trainIdx[fold]].transpose(2,0,1) # (trials, chans, samples)\n",
    "            t_val = data_tongue[subject, band][:,:,valIdx[fold]].transpose(2,0,1) # (trials, chans, samples)\n",
    "            OVR_val = data_OVR_tongue[subject, band][:,:,valIdx[fold]].transpose(2,0,1) # (trials, chans, samples)\n",
    "            t_test = test_data_tongue[subject, band][:,:,:].transpose(2,0,1) # (trials, chans, samples)\n",
    "            OVR_test = test_data_OVR_tongue[subject, band][:,:,:].transpose(2,0,1) # (trials, chans, samples)\n",
    "            train_data = np.stack((t_train,OVR_train), axis=0) # <- CSP input data format (classes, trials, chans, samples) \n",
    "            val_data = np.stack((t_val,OVR_val), axis=0) # <- CSP input data format (classes, trials, chans, samples)\n",
    "            test_data = np.stack((t_test,OVR_test), axis=0) # <- CSP input data format (classes, trials, chans, samples)\n",
    "\n",
    "\n",
    "            # Run Mahta's CSP code\n",
    "            # Source: https://github.com/mahtamsv/CCACSP\n",
    "            csp_filts, clf = train(train_data[0], train_data[1], csp_per_class)\n",
    "            train_prob = test(np.vstack(train_data), csp_filts, clf)\n",
    "            val_prob = test(np.vstack(val_data), csp_filts, clf)\n",
    "            test_prob = test(np.vstack(test_data), csp_filts, clf)\n",
    "            \n",
    "            # test() gives the prob of the 0th class, that's why \n",
    "            # we have y_val seemingly switched below\n",
    "            y_val = np.append(np.ones(12), np.zeros(12))\n",
    "            y_true = np.append(np.ones(72), np.zeros(72))\n",
    "\n",
    "            band_score_train[:,band] = train_prob\n",
    "            band_score_val[:,band] = val_prob\n",
    "            band_score_test[:,band] = test_prob\n",
    "\n",
    "        \n",
    "        \n",
    "        y_pred = np.rint(band_score_test.mean(1))\n",
    "        accuracy[subject,fold] = sum(y_pred==y_true)/len(y_true)\n",
    "        kappa[subject, fold] = cohen_kappa_score(y_pred, y_true)\n",
    "    print('===============')\n",
    "print(np.mean(accuracy, axis=1))\n",
    "print(np.mean(kappa, axis=1))\n",
    "tvo = np.mean(kappa, axis=1).tolist()\n",
    "\n",
    "# Main Analysis Over"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Subject 1': 0.21354166666666666,\n",
       " 'Subject 2': 0.09432870370370372,\n",
       " 'Subject 3': 0.2528935185185185,\n",
       " 'Subject 5': 0.08680555555555555,\n",
       " 'Subject 6': 0.020254629629629636,\n",
       " 'Subject 7': 0.4027777777777778,\n",
       " 'Subject 8': 0.26099537037037035,\n",
       " 'Subject 9': 0.24942129629629628}"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#kappa values\n",
    "avgKappa = {}\n",
    "for i in range(len(lvo)):\n",
    "    subject = i+1\n",
    "    avg = (lvo[i] + rvo[i] + fvo[i] + tvo[i])/4\n",
    "    if subject >= 4:\n",
    "        subject += 1\n",
    "    avgKappa[f\"Subject {subject}\"] = avg\n",
    "    \n",
    "avgKappa"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "CSE156",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
